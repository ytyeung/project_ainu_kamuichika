{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "import json\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "project_name = os.getenv('PROJECT_NAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The story id, from 1 to 13 according to the 13 Ainu Kamuy Yukars translated by Chiri Yukie. The Yukar ID starts at 1. Chiri's Preface is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_at = 11\n",
    "end_at = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Translation(BaseModel):\n",
    "    \"\"\"The updated translation, and the comments for the update\"\"\"\n",
    "    updated_translation: str = Field(description=\"The updated translation\")\n",
    "    comment: str = Field(description=\"Comments on the translation update\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_instruction_prompt = \"\"\"You are a professional translator. You know Japanese, English and Chinese. You can translate Japanese into either Chinese or English. You can also translation Chinese into English, and English into Chinese.\"\"\"\n",
    "\n",
    "client = genai.Client(\n",
    "      vertexai=True,\n",
    "      project=project_name,\n",
    "      location=\"us-central1\",\n",
    ")\n",
    "\n",
    "model = \"gemini-2.0-flash-001\"\n",
    "\n",
    "generate_content_config = types.GenerateContentConfig(\n",
    "    temperature = 0,\n",
    "    top_p = 0,\n",
    "    max_output_tokens = 8192,\n",
    "    response_mime_type = 'application/json',\n",
    "    response_schema = Translation,\n",
    "    safety_settings = [types.SafetySetting(\n",
    "      category=\"HARM_CATEGORY_HATE_SPEECH\",\n",
    "      threshold=\"OFF\"\n",
    "    ),types.SafetySetting(\n",
    "      category=\"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
    "      threshold=\"OFF\"\n",
    "    ),types.SafetySetting(\n",
    "      category=\"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
    "      threshold=\"OFF\"\n",
    "    ),types.SafetySetting(\n",
    "      category=\"HARM_CATEGORY_HARASSMENT\",\n",
    "      threshold=\"OFF\"\n",
    "    )],\n",
    "    system_instruction=[types.Part.from_text(text=system_instruction_prompt)],\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "reflection_prompt = \"\"\"You are translating the following Japanese text into Chinese. The original text is a Japanese translation of footnotes a Ainu chant. \n",
    "You have 2 versions of Chinese translations at hand.\n",
    "\n",
    "Here are your tasks:\n",
    "\n",
    "1. Compare the two Chinese translations with the original Japanese text. List out the Pros and Cons of the two Translations.\n",
    "2. Choose a better translation. Accuracy of meaning is the most important criterion. Easy to understand is the second.\n",
    "3. Based on the better translation, translate the Japanese text into Chinese again, incorporating the Pros of the two translations.\n",
    "\n",
    "Keep the original Japanese meaning accurately. Use modern Chinese for easy understanding. Display in Traditional Chinese. \n",
    "If a term cannot be translated, keep the original language.\n",
    "For the text which are not in Japanese, keep the original form. \n",
    "\n",
    "This is the Japanese text.\n",
    "{japanese_text}\n",
    "\n",
    "This is the Chinese Translation 1.\n",
    "{chinese_translation_1}\n",
    "\n",
    "This is the Chinese Translation 2.\n",
    "{chinese_translation_2}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(client: genai.Client,generate_content_config :types.GenerateContentConfig,model :str, /, prompt :str):\n",
    "\n",
    "    text_full_prompt = text1 = types.Part.from_text(text=f\"{prompt}\")\n",
    "\n",
    "    output = \"\"\n",
    "\n",
    "    contents = [\n",
    "      types.Content(\n",
    "        role=\"user\",\n",
    "        parts=[\n",
    "          text_full_prompt\n",
    "        ]\n",
    "      )\n",
    "    ]\n",
    "\n",
    "    for chunk in client.models.generate_content_stream(\n",
    "        model = model,\n",
    "        contents = contents,\n",
    "        config = generate_content_config,\n",
    "        ):\n",
    "        print(chunk.text, end=\"\")\n",
    "        output += chunk.text\n",
    "\n",
    "    return output\n",
    "\n",
    "def get_output_file_name_key(title :str):\n",
    "    # setup the output file name\n",
    "    s = title.split()\n",
    "    md_name_part = s[0]\n",
    "\n",
    "    name_2nd_part = \"\"\n",
    "\n",
    "    for text in s:\n",
    "        if text.startswith('“'):\n",
    "            name_2nd_part = text.replace('“', '').replace('”', '')\n",
    "        \n",
    "    md_name_part += \"_\" + name_2nd_part\n",
    "\n",
    "    return md_name_part\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the markdown template for writing the Chinese translations to Markdown file\n",
    "\n",
    "#read in the template\n",
    "with open(\"templates/iter1_output_md_template\", \"r\", encoding=\"utf8\") as f:\n",
    "    md_template = f.read()\n",
    "    md_template = unicodedata.normalize('NFKC', md_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the content page of Ainu original text and get the original title\n",
    "with open(\"original_Ainu_text/content.txt\", \"r\", encoding=\"utf8\") as f:\n",
    "    ainu_content = f.read()\n",
    "    ainu_content = unicodedata.normalize('NFKC', ainu_content)\n",
    "\n",
    "\n",
    "s=re.split(r'\\n\\n', ainu_content)\n",
    "ainu_titles = re.split(r'\\n', s[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"comment\": \"Analysis of the two Chinese translations:\\n\\nTranslation 1:\\nPros: More literal translation of \\\"六つの地獄\\\" as \\\"六個地獄\\\".\\nCons: Slightly less natural phrasing in the second sentence.\\n\\nTranslation 2:\\nPros: More natural and concise phrasing, especially in the second sentence.\\nCons: \\\"六つの地獄\\\" is translated as \\\"六層地獄\\\", which is not a direct translation.\\n\\nChoice of Better Translation: Translation 2 is better because it is more natural and easier to understand, while still maintaining the core meaning. However, the translation of \\\"六つの地獄\\\" can be improved.\\n\\nUpdated Translation Rationale: Incorporate the natural phrasing of Translation 2 while ensuring accurate translation of key terms. Use \\\"六層地獄\\\" to align with the concept of layered underworld.\",\n",
      "  \"updated_translation\": \"iwan poknashir......六層地獄。地底下有六層世界，各種惡魔居住在那裡。\"\n",
      "}"
     ]
    }
   ],
   "source": [
    "for song_no in range(start_at, end_at + 1):\n",
    "\n",
    "    md_name_part = get_output_file_name_key(ainu_titles[song_no - 1])\n",
    "\n",
    "    with open(f\"Initial_LLM_prompts_and_translations_footnotes/Chinese_Translation_JSON/{song_no}_{md_name_part}.json\", \"r\", encoding=\"utf8\") as f:\n",
    "        data_dict = json.load(f)\n",
    "\n",
    "    with open(f\"cross_lingual_LLM_prompts_and_translations_footnotes/Chinese_Translation_JSON/{song_no}_{md_name_part}.json\", \"r\", encoding=\"utf8\") as f:\n",
    "        data_dict_2 = json.load(f)\n",
    "\n",
    "    reflection_prompt_formatted = reflection_prompt.format(japanese_text=data_dict['japanese_translation'],\n",
    "                                                           chinese_translation_1=data_dict['chinese_translation'],\n",
    "                                                           chinese_translation_2=data_dict_2['chinese_translation'])\n",
    "\n",
    "    updated_translation = generate(client,generate_content_config,model,prompt = reflection_prompt_formatted)\n",
    "\n",
    "    updated_translation_dict = json.loads(updated_translation)\n",
    "    #print(updated_translation_dict['updated_translation'])\n",
    "    #print(updated_translation_dict['comment'])\n",
    "\n",
    "    data_dict['chinese_translation_1'] = data_dict['chinese_translation']\n",
    "    data_dict['chinese_translation_2'] = data_dict_2['chinese_translation']\n",
    "\n",
    "    del data_dict['chinese_translation']\n",
    "\n",
    "    data_dict['updated_chinese_translation'] = updated_translation_dict['updated_translation']\n",
    "    data_dict['comment'] = updated_translation_dict['comment']\n",
    "\n",
    "    md_output = md_template.format(translated_language=\"Chinese\", ainu_title=data_dict['ainu_title'],\n",
    "                formatted_prompt=reflection_prompt_formatted,\n",
    "                japanese_title=data_dict['japanese_title'], input_japanese = data_dict['japanese_translation'],\n",
    "                output= f\"{data_dict['updated_chinese_translation']}\\n\\n{data_dict['comment']}\")\n",
    "\n",
    "    with open(f\"Updated_LLM_prompts_and_translations_footnotes/Chinese_Translation_JSON/{song_no}_{md_name_part}.json\", \"w\", encoding=\"utf8\") as f:\n",
    "        json.dump(data_dict, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    with open(f\"Updated_LLM_prompts_and_translations_footnotes/Chinese_Translation/{song_no}_{md_name_part}.md\", \"w\", encoding=\"utf8\") as f:\n",
    "        f.write(md_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
