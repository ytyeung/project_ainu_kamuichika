{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import httpx\n",
    "import json\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "from typing import Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The story id, from 1 to 13 according to the 13 Ainu Kamuy Yukars translated by Chiri Yukie. The Yukar ID starts at 1. Chiri's Prologue is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_at = 0\n",
    "end_at = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the content page of Japanese translation and get the Japanese translated title\n",
    "with open(\"Chiri_Japanese_Translation/content.txt\", \"r\", encoding=\"utf8\") as f:\n",
    "    japanese_content = f.read()\n",
    "    japanese_content = unicodedata.normalize('NFKC', japanese_content)\n",
    "\n",
    "\n",
    "s=re.split(r'\\n\\n', japanese_content)\n",
    "japanese_titles = re.split(r'\\n', s[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the content page of Ainu original text and get the original title\n",
    "with open(\"original_Ainu_text/content.txt\", \"r\", encoding=\"utf8\") as f:\n",
    "    ainu_content = f.read()\n",
    "    ainu_content = unicodedata.normalize('NFKC', ainu_content)\n",
    "\n",
    "\n",
    "s=re.split(r'\\n\\n', ainu_content)\n",
    "ainu_titles = [\"\"] + re.split(r'\\n', s[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the markdown template\n",
    "\n",
    "#read in the template\n",
    "with open(\"templates/updated_output_md_template\", \"r\", encoding=\"utf8\") as f:\n",
    "    md_template = f.read()\n",
    "    md_template = unicodedata.normalize('NFKC', md_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_data(japanese_title: str, ainu_title: str, japanese_text: str, chinese_translation: Dict, english_translation: Dict, \n",
    "                eng_to_chi_translation: Dict, chi_to_eng_translation: Dict, updated_translation_zh: Dict, updated_translation_en: Dict):\n",
    "    output_dict = dict(japanese_title = japanese_title, ainu_title = ainu_title, japanese_text = japanese_text)\n",
    "    output_dict['chinese_translation'] = chinese_translation\n",
    "    output_dict['english_translation'] = english_translation\n",
    "    output_dict['eng_to_chi_translation'] = eng_to_chi_translation\n",
    "    output_dict['chi_to_eng_translation'] = chi_to_eng_translation\n",
    "    output_dict['updated_translation_zh'] = updated_translation_zh\n",
    "    output_dict['updated_translation_en'] = updated_translation_en\n",
    "\n",
    "    return output_dict\n",
    "\n",
    "def get_output_file_name_key(title :str):\n",
    "    # setup the output file name\n",
    "    s = title.split()\n",
    "    md_name_part = s[0]\n",
    "\n",
    "    name_2nd_part = \"\"\n",
    "\n",
    "    for text in s:\n",
    "        if text.startswith('“'):\n",
    "            name_2nd_part = text.replace('“', '').replace('”', '')\n",
    "        \n",
    "    md_name_part += \"_\" + name_2nd_part\n",
    "\n",
    "    return md_name_part\n",
    "\n",
    "def format_markdown(md_template, target_language, ainu_titles,japanese_titles,song_no, translation_score,updated_translation):\n",
    "    md_output = md_template.format(ainu_title=ainu_titles[song_no], japanese_title=japanese_titles[song_no], translated_title = updated_translation['title'],\n",
    "                                target_language = target_language,\n",
    "                                system_prompt = '',\n",
    "                                formatted_prompt = '',\n",
    "                                score_accuracy_1 = translation_score['translation_score'][0]['score_accuracy'],\n",
    "                                score_accuracy_2 = translation_score['translation_score'][1]['score_accuracy'],\n",
    "                                score_understanding_1 = translation_score['translation_score'][0]['score_easy_understanding'],\n",
    "                                score_understanding_2 = translation_score['translation_score'][1]['score_easy_understanding'],\n",
    "                                weighted_score_1 = translation_score['translation_score'][0]['weighted_score'],\n",
    "                                weighted_score_2 = translation_score['translation_score'][1]['weighted_score'],\n",
    "                                translation_1 = translation_score['translation_score'][0]['text'],\n",
    "                                translation_2 = translation_score['translation_score'][1]['text'],\n",
    "                                comment_1 = translation_score['translation_score'][0]['comment'],\n",
    "                                comment_2 = translation_score['translation_score'][1]['comment'],\n",
    "                                better_choice = translation_score['better_translation'],\n",
    "                                better_comment = translation_score['better_translation_comment'],\n",
    "                                output = updated_translation['translation'],\n",
    "                                score_poetic_1 = translation_score['translation_score'][0]['score_poetic_flow'],\n",
    "                                score_poetic_2 = translation_score['translation_score'][1]['score_poetic_flow'],\n",
    "                            )\n",
    "\n",
    "    return md_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Song 0\n"
     ]
    }
   ],
   "source": [
    "for song_no in range(start_at,end_at+1):\n",
    "    print (f\"Processing Song {song_no}\")\n",
    "\n",
    "    with open(f\"Chiri_Japanese_Translation/prologue.txt\", \"r\", encoding=\"utf8\") as f:\n",
    "        japanese_story = f.read()\n",
    "        japanese_story = unicodedata.normalize('NFKC', japanese_story)\n",
    "\n",
    "    session = f\"http://localhost:8000/apps/translation_agent_adk/users/default_user_{song_no}/sessions/default_user_session_{song_no}\"\n",
    "\n",
    "    r = httpx.post(session)\n",
    "\n",
    "    input_data = {\n",
    "        \"app_name\": \"translation_agent_adk\",\n",
    "        \"user_id\": f\"default_user_{song_no}\",\n",
    "        \"session_id\": f\"default_user_session_{song_no}\",\n",
    "        \"new_message\": {\n",
    "            \"role\": \"user\",\n",
    "            \"parts\": [{\n",
    "            \"text\": \"This is the text to be translated. Text type is PROLOGUE: \\n\" + japanese_story\n",
    "            }]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    input_json = json.dumps(input_data, ensure_ascii=False)\n",
    "    async with httpx.AsyncClient() as client:\n",
    "        response = await client.post(\n",
    "            url=\"http://0.0.0.0:8000/run\",\n",
    "            data=input_json,\n",
    "            timeout=None,\n",
    "        )\n",
    "\n",
    "    r = httpx.delete(session)\n",
    "\n",
    "    response_json = response.json()\n",
    "    english_translation = json.loads(response_json[0]['content']['parts'][0]['text'])['translation']\n",
    "    chinese_translation = json.loads(response_json[1]['content']['parts'][0]['text'])['translation']\n",
    "    eng_to_chi_translation = json.loads(response_json[2]['content']['parts'][0]['text'])['translation']\n",
    "    chi_to_eng_translation = json.loads(response_json[3]['content']['parts'][0]['text'])['translation']\n",
    "    translation_score_zh = json.loads(response_json[4]['content']['parts'][0]['text'])\n",
    "    translation_score_en = json.loads(response_json[6]['content']['parts'][0]['text'])\n",
    "    updated_translation_zh = json.loads(response_json[5]['content']['parts'][0]['text'])\n",
    "    updated_translation_en = json.loads(response_json[7]['content']['parts'][0]['text'])\n",
    "\n",
    "    output_dict = output_data(japanese_title=japanese_titles[song_no], ainu_title=ainu_titles[song_no], \n",
    "                            japanese_text=japanese_story, chinese_translation=chinese_translation,\n",
    "                            english_translation=english_translation, eng_to_chi_translation=eng_to_chi_translation,\n",
    "                            chi_to_eng_translation=chi_to_eng_translation, updated_translation_zh=updated_translation_zh,\n",
    "                            updated_translation_en=updated_translation_en)\n",
    "\n",
    "    #md_name_part = get_output_file_name_key(ainu_titles[song_no])\n",
    "\n",
    "    with open(f\"AgenticTranslationOutput_adk_main_text/json/Chiri_Yukie_Prologue.json\",\"w\", encoding=\"utf8\") as f:\n",
    "        json.dump(output_dict, f, ensure_ascii=False, indent=4)\n",
    "        \n",
    "    with open(f\"AgenticTranslationOutput_adk_main_text/raw/Chiri_Yukie_Prologue.json\",\"w\", encoding=\"utf8\") as f:\n",
    "        f.write(response.text)\n",
    "    \n",
    "    md_output_zh = format_markdown(md_template, \"Chinese\", ainu_titles,japanese_titles,song_no, translation_score_zh, updated_translation_zh)\n",
    "\n",
    "    with open(f\"AgenticTranslationOutput_adk_main_text/markdown_Chinese/Chiri_Yukie_Prologue.md\",\"w\", encoding=\"utf8\") as f:\n",
    "        f.write(md_output_zh)\n",
    "\n",
    "    md_output_en = format_markdown(md_template, \"English\", ainu_titles,japanese_titles,song_no, translation_score_en, updated_translation_en)\n",
    "\n",
    "    with open(f\"AgenticTranslationOutput_adk_main_text/markdown_English/Chiri_Yukie_Prologue.md\",\"w\", encoding=\"utf8\") as f:\n",
    "        f.write(md_output_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
